name: Build - ACS
on:
  push:
  workflow_dispatch:
    inputs:
      data_year:
        description: 'Release year of ACS data. e.g. For 2015-2019 acs5 data, type "2019"'
        required: true
        default: '2019'
      geo_year:
        description: 'Year of geographic units. Options: "2010", "2020", or "2010_to_2020"'
        required: true
        default: '2010_to_2020'

jobs:
  build:
    if: >-
      contains(github.event.head_commit.message, '[acs]') ||
      github.event_name == 'workflow_dispatch'
    name: Build ACS PFF outputs
    env:
      API_KEY: ${{ secrets.API_KEY }}
      EDM_DATA: ${{ secrets.EDM_DATA }}
      DATA_YEAR: ${{ github.event.inputs.data_year }}
      GEO_YEAR: ${{ github.event.inputs.geo_year }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install locally
        run: |
          python3.9 -m pip install --upgrade pip
          python3.9 -m pip install .

      - name: run pipelines/acs
        run: python3.9 pipelines/acs/build.py $DATA_YEAR $GEO_YEAR

      - name: send to database
        run: |
          psql $EDM_DATA -c "
          DROP TABLE IF EXISTS pff_acs.\"test-$DATA_YEAR\";
          CREATE TABLE pff_acs.\"test-$DATA_YEAR\" (
              census_geoid text,
              pff_variable text,
              geotype text,
              c double precision,
              e double precision,
              m double precision,
              p double precision,
              z double precision,
              domain text
          );
          "
          cat pff_output/acs_$DATA_YEAR_$GEO_YEAR_geogs.csv | psql $EDM_DATA -c "
            COPY pff_acs.\"test-$DATA_YEAR\" FROM STDIN DELIMITER ',' CSV HEADER;
          "
