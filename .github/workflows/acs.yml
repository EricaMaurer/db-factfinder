name: Build - ACS
on:
  push:
  workflow_dispatch:
    inputs:
      data_year:
        description: 'Release year of ACS data. For example, to process 2015-2019 5-year data, type "2019"'
        required: true
      geo_year:
        description: 'Year of geographic units. Current options are "2010", "2020", or "2010_to_2020"'
        required: true

jobs: 
  build:
    if: >- 
      contains(github.event.head_commit.message, '[acs]') ||
      github.event_name == 'workflow_dispatch'
    name: Build ACS PFF outputs
    env:
      API_KEY: ${{ secrets.API_KEY }}
      EDM_DATA: ${{ secrets.EDM_DATA }}
      DATA_YEAR: ${{ github.event.inputs.data_year }}
      GEO_YEAR: ${{ github.event.inputs.geo_year }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install locally
        run: |
          python3.9 -m pip install --upgrade pip
          python3.9 -m pip install .

      - name: run pipelines/acs
        run: python3.9 pipelines/acs/build.py $DATA_YEAR $GEO_YEAR 

      - name: upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: my-artifact
          path: pff_output/
          retention-days: 2

      - name: send to database
        run: |
          psql $EDM_DATA -c "
          DROP TABLE IF EXISTS pff_acs.\"$DATA_YEAR-acs-$GEO_YEAR-geo\";
          CREATE TABLE pff_acs.\"$DATA_YEAR-acs-$GEO_YEAR-geo\" (
              census_geoid text,
              pff_variable text,
              geotype text,
              c double precision,
              e double precision,
              m double precision,
              p double precision,
              z double precision,
              domain text
          );
          "
          cat pff_acs.csv | psql $EDM_DATA -c "
            COPY pff_acs.\"$DATA_YEAR-acs-$GEO_YEAR-geo\" FROM STDIN DELIMITER ',' CSV HEADER;
          "
